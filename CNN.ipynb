{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 3\n",
    "learnin_rate = 0.0005\n",
    "num_epochs = 10\n",
    "input_size=np.asarray((128,64,1))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('images_perso.pth')\n",
    "labels = torch.load('labels_perso.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x = dataset\n",
    "        self.y = labels\n",
    "        self.n_samples = len(dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_size = int(len(dataset) * .7)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "hand_dataset = handDataset()\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(hand_dataset, [train_size, test_size], generator=generator)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*64*3,500) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.flatten(x)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_model, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        size=input_size-5+1\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        size=size/2\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        size=size-3+1\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        size=size/2\n",
    "        print(size)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(int(size[0])*int(size[1])*64,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.max_pool1(out)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool2(out)\n",
    "        out = self.flatten(out)\n",
    "        #896x14 and 12544x128)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.   14.   -1.75]\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN_model(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(cnn_model.parameters(), lr=learnin_rate, weight_decay=0.005, momentum=0.9)\n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m cnn_model(images)\n\u001b[1;32m----> 8\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\hpesq\\OneDrive\\Bureau\\TSP\\Computer vision part 2\\tsp-vision\\tsp-vision-venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hpesq\\OneDrive\\Bureau\\TSP\\Computer vision part 2\\tsp-vision\\tsp-vision-venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hpesq\\OneDrive\\Bureau\\TSP\\Computer vision part 2\\tsp-vision\\tsp-vision-venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hpesq\\OneDrive\\Bureau\\TSP\\Computer vision part 2\\tsp-vision\\tsp-vision-venv\\Lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'),\n",
      "indices=tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0'))\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0'))\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "Accuracy of the network on the 126 test images: 100.0 %\n",
      "TIme of inference =0.0006547277777523656s\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start = timer()\n",
    "    for images, labels in test_loader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        labels_class=torch.max(labels,1)\n",
    "        print(labels_class)\n",
    "        for i,sample in enumerate(labels_class[1]):\n",
    "            #print(sample)\n",
    "            #print(predicted[i])\n",
    "            if sample==predicted[i]:\n",
    "                correct += 1\n",
    "    end=timer()\n",
    "    \n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "    print(\"TIme of inference =\" + str((end-start)/total) +\"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1598, -0.0731]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "tr = transforms.Compose([\n",
    "        transforms.Resize((128, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.RandomHorizontalFlip(),  \n",
    "        #transforms.RandomRotation(90),  \n",
    "        #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  \n",
    "        transforms.Normalize(mean=[0], std=[0.5])  # Normalizing mean and std values\n",
    "    ])\n",
    "image = Image.open(\"./validation/poing.jpeg\").convert('L')\n",
    "display(image)\n",
    "image_tensor = tr(image)\n",
    "image_tensor=image_tensor.to(device)\n",
    "image_batch = image_tensor.unsqueeze(0)\n",
    "predicted=cnn_model(image_batch)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## affichage des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4812), started 2:44:33 ago. (Use '!kill 4812' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-71e7a2e6d1273881\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-71e7a2e6d1273881\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_path = \"./WIN_20240111_10_48_03_Pro (2).jpg\"\n",
    "img = cv.imread(img_path)\n",
    "fgbg = cv.createBackgroundSubtractorMOG2()\n",
    "fgmask = fgbg.apply(img)\n",
    "array_im=cv.cvtColor(fgmask, cv.COLOR_BGR2RGB)\n",
    "pil_image=Image.fromarray(array_im)\n",
    "pil_image.show()\n",
    "hsvim = cv.cvtColor(img, cv.COLOR_BGR2HSV) \n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\") \n",
    "upper = np.array([50, 255, 255], dtype = \"uint8\") \n",
    "skinRegionHSV = cv.inRange (hsvim, lower, upper) \n",
    "blurred= cv.blur (skinRegionHSV, (2,2))\n",
    "ret, thresh = cv.threshold (blurred, 0,255, cv. THRESH_BINARY) \n",
    "array_im=cv.cvtColor(thresh, cv.COLOR_BGR2RGB)\n",
    "pil_image=Image.fromarray(array_im)\n",
    "pil_image.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(cnn_model) # Export to TorchScript\n",
    "model_scripted.save('sauvegarde.pt') # Save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
